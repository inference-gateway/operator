---
apiVersion: v1
kind: Namespace
metadata:
  name: inference-gateway
  labels:
    inference-gateway.com/managed: "true"
---
apiVersion: core.inference-gateway.com/v1alpha1
kind: Gateway
metadata:
  name: inference-gateway
  namespace: inference-gateway
spec:
  environment: development
  image: "ghcr.io/inference-gateway/inference-gateway:0.12.0"
  providers:
    - name: OpenAI
      env:
        - name: OPENAI_API_URL
          valueFrom:
            configMapKeyRef:
              name: inference-gateway-config
              key: OPENAPI_API_URL
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: inference-gateway-providers-secret
              key: OPENAI_API_KEY
  ingress:
    enabled: true
    host: "api.inference-gateway.local"
    # Defaults:
    # - className: "nginx" (auto-detected)
    # - path: "/" with pathType: "Prefix"
    # - TLS enabled with auto-generated secret name
    # - cert-manager issuer based on environment (development = selfsigned-issuer)
  resources:
    requests:
      cpu: "100m"
      memory: "128Mi"
    limits:
      cpu: "500m"
      memory: "512Mi"
---
apiVersion: v1
kind: Secret
metadata:
  name: inference-gateway-providers-secret
  namespace: inference-gateway
type: Opaque
stringData:
  OPENAI_API_KEY: ""
  ANTHROPIC_API_KEY: ""
  GROQ_API_KEY: ""
  COHERE_API_KEY: ""
  CLOUDFLARE_API_KEY: ""
  DEEPSEEK_API_KEY: ""
  OLLAMA_API_KEY: ""
  CUSTOM_API_KEY: ""

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: inference-gateway-config
  namespace: inference-gateway
data:
  OPENAPI_API_URL: "https://api.openai.com/v1"
  ANTHROPIC_API_URL: "https://api.anthropic.com/v1"
  GROQ_API_URL: "https://api.groq.com/openai/v1"
  COHERE_API_URL: "https://api.cohere.ai"
  CLOUDFLARE_API_URL: "https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai"
  DEEPSEEK_API_URL: "https://api.deepseek.com"
  OLLAMA_API_URL: "http://ollama:11434/v1"
  CUSTOM_API_URL: "http://your-domain.example.local:8080/v1"
