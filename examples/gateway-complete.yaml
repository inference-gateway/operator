---
apiVersion: v1
kind: Namespace
metadata:
  name: inference-gateway
  labels:
    inference-gateway.com/managed: "true"
---
apiVersion: core.inference-gateway.com/v1alpha1
kind: Gateway
metadata:
  name: inference-gateway
  namespace: inference-gateway
spec:
  # Core gateway configuration
  environment: development
  hpa:
    enabled: true
    config:
      minReplicas: 3
      maxReplicas: 10
      metrics:
        - type: Resource
          resource:
            name: cpu
            target:
              type: Utilization
              averageUtilization: 80
  image: "ghcr.io/inference-gateway/inference-gateway:0.12.0"

  # OpenTelemetry observability configuration
  telemetry:
    enabled: true
    metrics:
      enabled: true
      port: 9464

  # Server configuration
  server:
    # port: 8080
    timeouts:
      read: "60s"
      write: "60s"
      idle: "300s"
    tls:
      enabled: false
      # Default behavior: If enabled is true and no custom secret is specified, the controller will automatically mount the
      # same TLS secret used by the Ingress (inference-gateway-tls) into the backend pod for end-to-end TLS.
      # To override, specify certificateRef and keyRef explicitly.

  # Authentication configuration
  auth:
    enabled: false
    provider: oidc
    oidc:
      issuerUrl: "https://keycloak.inference-gateway.local/realms/inference-gateway-realm"
      clientId: "inference-gateway-client"
      clientSecretRef:
        name: inference-gateway-auth-secret
        key: OIDC_CLIENT_SECRET

  # AI Provider configurations
  providers:
    - name: OpenAI
      enabled: false
      env:
        - name: OPENAI_API_URL
          valueFrom:
            configMapKeyRef:
              name: inference-gateway-config
              key: OPENAPI_API_URL
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: inference-gateway-providers-secret
              key: OPENAI_API_KEY
    - name: Anthropic
      enabled: false
      env:
        - name: ANTHROPIC_API_URL
          valueFrom:
            configMapKeyRef:
              name: inference-gateway-config
              key: ANTHROPIC_API_URL
        - name: ANTHROPIC_API_KEY
          valueFrom:
            secretKeyRef:
              name: inference-gateway-providers-secret
              key: ANTHROPIC_API_KEY
    - name: Groq
      enabled: true
      env:
        - name: GROQ_API_URL
          valueFrom:
            configMapKeyRef:
              name: inference-gateway-config
              key: GROQ_API_URL
        - name: GROQ_API_KEY
          valueFrom:
            secretKeyRef:
              name: inference-gateway-providers-secret
              key: GROQ_API_KEY
    - name: Cohere
      enabled: true
      env:
        - name: COHERE_API_URL
          valueFrom:
            configMapKeyRef:
              name: inference-gateway-config
              key: COHERE_API_URL
        - name: COHERE_API_KEY
          valueFrom:
            secretKeyRef:
              name: inference-gateway-providers-secret
              key: COHERE_API_KEY
    - name: Cloudflare
      enabled: true
      env:
        - name: CLOUDFLARE_API_URL
          valueFrom:
            configMapKeyRef:
              name: inference-gateway-config
              key: CLOUDFLARE_API_URL
        - name: CLOUDFLARE_API_KEY
          valueFrom:
            secretKeyRef:
              name: inference-gateway-providers-secret
              key: CLOUDFLARE_API_KEY
    - name: DeepSeek
      enabled: true
      env:
        - name: DEEPSEEK_API_URL
          valueFrom:
            configMapKeyRef:
              name: inference-gateway-config
              key: DEEPSEEK_API_URL
        - name: DEEPSEEK_API_KEY
          valueFrom:
            secretKeyRef:
              name: inference-gateway-providers-secret
              key: DEEPSEEK_API_KEY
    - name: Ollama
      enabled: true
      env:
        - name: OLLAMA_API_URL
          valueFrom:
            configMapKeyRef:
              name: inference-gateway-config
              key: OLLAMA_API_URL
        - name: OLLAMA_API_KEY
          valueFrom:
            secretKeyRef:
              name: inference-gateway-providers-secret
              key: OLLAMA_API_KEY
    - name: Custom
      enabled: true
      env:
        - name: CUSTOM_API_URL
          valueFrom:
            configMapKeyRef:
              name: inference-gateway-config
              key: CUSTOM_API_URL
        - name: CUSTOM_API_KEY
          valueFrom:
            secretKeyRef:
              name: inference-gateway-providers-secret
              key: CUSTOM_API_KEY

  # Model Context Protocol configuration
  mcp:
    enabled: false
    expose: false
    timeouts:
      client: "10s"
      dial: "5s"
      tlsHandshake: "5s"
      responseHeader: "5s"
      request: "10s"
    servers:
      - name: filesystem-server
        url: "http://mcp-filesystem.mcp.svc.cluster.local:8080"
        healthCheck:
          enabled: true
          path: "/health"
          interval: "30s"
      - name: git-server
        url: "http://mcp-git.mcp.svc.cluster.local:8080"
        healthCheck:
          enabled: true
          path: "/health"
          interval: "30s"

  # Agent-to-Agent configuration
  a2a:
    enabled: false
    expose: false
    timeouts:
      client: "60s"
    polling:
      enabled: true
      interval: "2s"
      timeout: "60s"
      maxAttempts: 30
    # Service Discovery configuration for automatic agent discovery
    serviceDiscovery:
      enabled: false
      namespace: "agents"  # Search for agents in 'agents' namespace
      labelSelector: "inference-gateway.com/a2a-agent=true"  # Default label selector
      pollingInterval: "30s"  # Poll for new agents every 30 seconds
    agents:
      - name: google-calendar-agent
        url: "http://google-calendar-agent.agents.svc.cluster.local:8080"
        healthCheck:
          enabled: true
          path: "/health"
          interval: "30s"
      - name: email-agent
        url: "http://email-agent.agents.svc.cluster.local:8080"
        healthCheck:
          enabled: true
          path: "/health"
          interval: "30s"

  # Resource management
  resources:
    requests:
      cpu: "100m"
      memory: "128Mi"
    limits:
      cpu: "1000m"
      memory: "512Mi"

  # Ingress configuration
  ingress:
    enabled: true
    host: "api.inference-gateway.local"
    annotations:
      cert-manager.io/cluster-issuer: "selfsigned-cluster-issuer"
    tls:
      enabled: true
      secretName: inference-gateway-tls
---
apiVersion: v1
kind: Secret
metadata:
  name: inference-gateway-auth-secret
  namespace: inference-gateway
type: Opaque
stringData:
  OIDC_CLIENT_SECRET: ""
# ---
# apiVersion: v1
# kind: Secret
# metadata:
#   name: inference-gateway-providers-secret
#   namespace: inference-gateway
# type: Opaque
# stringData:
#   OPENAI_API_KEY: ""
#   ANTHROPIC_API_KEY: ""
#   GROQ_API_KEY: ""
#   COHERE_API_KEY: ""
#   CLOUDFLARE_API_KEY: ""
#   DEEPSEEK_API_KEY: ""
#   OLLAMA_API_KEY: ""
#   CUSTOM_API_KEY: ""
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: inference-gateway-config
  namespace: inference-gateway
data:
  OPENAPI_API_URL: "https://api.openai.com/v1"
  ANTHROPIC_API_URL: "https://api.anthropic.com/v1"
  GROQ_API_URL: "https://api.groq.com/openai/v1"
  COHERE_API_URL: "https://api.cohere.ai"
  CLOUDFLARE_API_URL: "https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai"
  DEEPSEEK_API_URL: "https://api.deepseek.com"
  OLLAMA_API_URL: "http://ollama:11434/v1"
  CUSTOM_API_URL: "http://your-domain.example.local:8080/v1"
