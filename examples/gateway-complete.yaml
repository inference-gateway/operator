---
apiVersion: v1
kind: Namespace
metadata:
  name: inference-gateway
  labels:
    inference-gateway.com/managed: "true"
---
apiVersion: core.inference-gateway.com/v1alpha1
kind: Gateway
metadata:
  name: inference-gateway
  namespace: inference-gateway
  labels:
    app.kubernetes.io/name: inference-gateway
    app.kubernetes.io/instance: inference-gateway
    app.kubernetes.io/component: api-gateway
    app.kubernetes.io/part-of: inference-gateway
    app.kubernetes.io/version: "0.12.0"
spec:
  # Core gateway configuration
  environment: production
  hpa:
    enabled: true
    minReplicas: 1
    maxReplicas: 10
    targetCPUUtilizationPercentage: 80
  image: "ghcr.io/inference-gateway/inference-gateway:0.12.0"

  # OpenTelemetry observability configuration
  telemetry:
    enabled: true
    metrics:
      enabled: true
      port: 9464 # Prometheus metrics endpoint
    tracing:
      enabled: true
      endpoint: "http://jaeger:14268/api/traces" # OTLP trace endpoint

  # Server configuration
  server:
    host: "0.0.0.0"
    port: 8080
    timeouts:
      read: "60s"
      write: "60s"
      idle: "300s"
    tls:
      enabled: true
      certificateRef:
        name: inference-gateway-tls
        key: tls.crt
      keyRef:
        name: inference-gateway-tls
        key: tls.key

  # Authentication configuration
  auth:
    enabled: true
    provider: oidc
    oidc:
      issuerUrl: "https://keycloak.inference-gateway.local/realms/inference-gateway-realm"
      clientId: "inference-gateway-client"
      clientSecretRef:
        name: inference-gateway-secrets
        key: OIDC_CLIENT_SECRET

  # AI Provider configurations
  providers:
    - name: openai
      type: openai
      config:
        baseUrl: "https://api.openai.com/v1"
        authType: bearer
        tokenRef:
          name: inference-gateway-secrets
          key: OPENAI_API_KEY
    - name: anthropic
      type: anthropic
      config:
        baseUrl: "https://api.anthropic.com/v1"
        authType: bearer
        tokenRef:
          name: inference-gateway-secrets
          key: ANTHROPIC_API_KEY
    - name: local-ollama
      type: ollama
      config:
        baseUrl: "http://ollama.ollama.svc.cluster.local:8080/v1"
        authType: none

  # Model Context Protocol configuration
  mcp:
    enabled: true
    expose: false
    timeouts:
      client: "10s"
      dial: "5s"
      tlsHandshake: "5s"
      responseHeader: "5s"
      request: "10s"
    servers:
      - name: filesystem-server
        url: "http://mcp-filesystem.mcp.svc.cluster.local:8080"
        healthCheck:
          enabled: true
          path: "/health"
          interval: "30s"
      - name: git-server
        url: "http://mcp-git.mcp.svc.cluster.local:8080"
        healthCheck:
          enabled: true
          path: "/health"
          interval: "30s"

  # Agent-to-Agent configuration
  a2a:
    enabled: true
    expose: false
    timeouts:
      client: "60s"
    polling:
      enabled: true
      interval: "2s"
      timeout: "60s"
      maxAttempts: 30
    agents:
      - name: google-calendar-agent
        url: "http://google-calendar-agent.agents.svc.cluster.local:8080"
        healthCheck:
          enabled: true
          path: "/health"
          interval: "30s"
      - name: email-agent
        url: "http://email-agent.agents.svc.cluster.local:8080"
        healthCheck:
          enabled: true
          path: "/health"
          interval: "30s"

  # Resource management
  resources:
    requests:
      cpu: "100m"
      memory: "128Mi"
    limits:
      cpu: "1000m"
      memory: "512Mi"

  # Service configuration
  service:
    type: ClusterIP
    port: 8080
    annotations: {}

  # Ingress configuration
  ingress:
    enabled: true
    host: "api.inference-gateway.local"
    className: "nginx"
    tls:
      enabled: true
      issuer: "letsencrypt-prod"
---
apiVersion: v1
kind: Secret
metadata:
  name: inference-gateway-secrets
  namespace: inference-gateway
  labels:
    app.kubernetes.io/name: inference-gateway
    app.kubernetes.io/instance: inference-gateway
    app.kubernetes.io/component: secrets
    app.kubernetes.io/part-of: inference-gateway
    app.kubernetes.io/version: "0.12.0"
type: Opaque
stringData:
  OIDC_CLIENT_SECRET: ""

  OPENAI_API_KEY: ""
  ANTHROPIC_API_KEY: ""
  GROQ_API_KEY: ""
  COHERE_API_KEY: ""
  CLOUDFLARE_API_KEY: ""
  DEEPSEEK_API_KEY: ""
  OLLAMA_API_KEY: ""
