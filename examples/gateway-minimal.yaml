---
apiVersion: v1
kind: Namespace
metadata:
  name: inference-gateway
  labels:
    inference-gateway.com/managed: "true"
---
apiVersion: core.inference-gateway.com/v1alpha1
kind: Gateway
metadata:
  name: simple-gateway
  namespace: inference-gateway
spec:
  # Minimal configuration for development
  replicas: 1
  image: "ghcr.io/inference-gateway/inference-gateway:latest"
  environment: development

  # Enable basic OpenTelemetry observability
  telemetry:
    enabled: true
    metrics:
      enabled: true
      port: 9464 # Prometheus endpoint

  # Simple server configuration
  server:
    host: "0.0.0.0"
    port: 8080

  # Single OpenAI provider
  providers:
    - name: openai
      type: openai
      config:
        baseUrl: "https://api.openai.com/v1"
        authType: bearer
        tokenRef:
          name: openai-secret
          key: api_key
---
apiVersion: v1
kind: Secret
metadata:
  name: openai-secret
  namespace: inference-gateway
  labels:
    app.kubernetes.io/name: inference-gateway
    app.kubernetes.io/instance: inference-gateway
    app.kubernetes.io/component: secrets
    app.kubernetes.io/part-of: inference-gateway
    app.kubernetes.io/version: "0.12.0"
type: Opaque
stringData:
  OIDC_CLIENT_SECRET: ""

  api_key: ""
