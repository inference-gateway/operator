---
apiVersion: v1
kind: Namespace
metadata:
  name: inference-gateway
  labels:
    inference-gateway.com/managed: "true"
---
apiVersion: core.inference-gateway.com/v1alpha1
kind: Gateway
metadata:
  name: inference-gateway-advanced
  namespace: inference-gateway
spec:
  # Core gateway configuration
  environment: production
  image: "ghcr.io/inference-gateway/inference-gateway:0.12.0"

  # AI Provider configurations
  providers:
    - name: OpenAI
      env:
        - name: OPENAI_API_URL
          valueFrom:
            configMapKeyRef:
              name: inference-gateway-config
              key: OPENAPI_API_URL
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: inference-gateway-providers-secret
              key: OPENAI_API_KEY

  # Advanced ingress configuration with custom settings
  ingress:
    enabled: true
    className: "nginx"
    annotations:
      # Custom annotations for advanced features
      nginx.ingress.kubernetes.io/rate-limit: "100"
      nginx.ingress.kubernetes.io/rate-limit-window: "1m"
      nginx.ingress.kubernetes.io/proxy-body-size: "10m"
      nginx.ingress.kubernetes.io/cors-allow-origin: "https://ui.inference-gateway.local"

    # Multiple hosts configuration (advanced usage)
    hosts:
      - host: "api.inference-gateway.local"
        paths:
          - path: "/"
            pathType: "Prefix"
      - host: "gateway.example.com"
        paths:
          - path: "/v1"
            pathType: "Prefix"
          - path: "/health"
            pathType: "Exact"

    # Advanced TLS configuration
    tls:
      enabled: true
      issuer: "letsencrypt-prod"
      config:
        - secretName: "api-inference-gateway-tls"
          hosts:
            - "api.inference-gateway.local"
        - secretName: "gateway-example-tls"
          hosts:
            - "gateway.example.com"

  # Resource management
  resources:
    requests:
      cpu: "100m"
      memory: "128Mi"
    limits:
      cpu: "1000m"
      memory: "512Mi"
---
apiVersion: v1
kind: Secret
metadata:
  name: inference-gateway-providers-secret
  namespace: inference-gateway
type: Opaque
stringData:
  OPENAI_API_KEY: ""
  ANTHROPIC_API_KEY: ""
  GROQ_API_KEY: ""
  COHERE_API_KEY: ""
  CLOUDFLARE_API_KEY: ""
  DEEPSEEK_API_KEY: ""
  OLLAMA_API_KEY: ""
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: inference-gateway-config
  namespace: inference-gateway
data:
  OPENAPI_API_URL: "https://api.openai.com/v1"
  ANTHROPIC_API_URL: "https://api.anthropic.com/v1"
  GROQ_API_URL: "https://api.groq.com/v1"
  COHERE_API_URL: "https://api.cohere.com/v1"
  CLOUDFLARE_API_URL: "https://api.cloudflare.com/v1"
  DEEPSEEK_API_URL: "https://api.deepseek.com/v1"
  OLLAMA_API_URL: "http://localhost:11434"
  CUSTOM_API_URL: "http://localhost:8080"
